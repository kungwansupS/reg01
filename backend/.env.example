# =============================================================================
# ENVIRONMENT CONFIGURATION (Example)
# =============================================================================

# =============================================================================
# 1. LLM PROVIDER (เลือกใช้เพียง 1 ค่า)
#    - gemini
#    - openai   (รวม Groq / External OpenAI-compatible)
#    - local    (Ollama / vLLM)
# =============================================================================
LLM_PROVIDER=openai


# =============================================================================
# 1.1 Google Gemini
# =============================================================================
GEMINI_API_KEY=
GEMINI_MODEL_NAME=gemini-3-flash


# =============================================================================
# 1.2 OpenAI / Groq / OpenAI-Compatible
# =============================================================================
OPENAI_API_KEY=
OPENAI_API_KEY2=
# OPENAI_API_KEY_BACKUP=
# Optional: comma-separated keys (used with OPENAI_API_KEY/OPENAI_API_KEY2)
# OPENAI_API_KEYS=
OPENAI_BASE_URL=https://api.groq.com/openai/v1
OPENAI_MODEL_NAME=openai/gpt-oss-120b
# OPENAI_MODEL_NAME=gpt-5-nano


# =============================================================================
# 1.3 Local Model (Ollama / vLLM)
# =============================================================================
LOCAL_API_KEY=ollama
LOCAL_BASE_URL=http://localhost:11434/v1
LOCAL_MODEL_NAME=iapp/chinda-qwen3-4b


# =============================================================================
# 2. SERVER & NETWORK
# =============================================================================
HOST=0.0.0.0
PORT=5000
ALLOWED_ORIGINS=*


# =============================================================================
# 3. CLOUDFLARE TUNNEL
# =============================================================================
# true  = ใช้ Quick Tunnel (ไม่ต้องมีโดเมน)
# false = ใช้ Named Tunnel
USE_QUICK_TUNNEL=true
CLOUDFLARE_TUNNEL_NAME=reg01-tunnel


# =============================================================================
# 4. FACEBOOK MESSENGER WEBHOOK
# =============================================================================
FB_VERIFY_TOKEN=verify123
FB_PAGE_ACCESS_TOKEN=
# Required to verify X-Hub-Signature-256 on incoming webhook requests
FB_APP_SECRET=


# =============================================================================
# 5. RAG / KNOWLEDGE BASE
# =============================================================================
USE_RETRIEVAL_ENGINE=true
RAG_STARTUP_EMBEDDING=true
RAG_STARTUP_PROCESS_PDF=true
RAG_STARTUP_BUILD_HYBRID=true

# PDF_INPUT_FOLDER=./static/docs
# PDF_QUICK_USE_FOLDER=./static/quick_use


# =============================================================================
# 6. DATABASE (PostgreSQL)
# =============================================================================
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/reg01
DB_POOL_MIN_SIZE=2
DB_POOL_MAX_SIZE=10


# =============================================================================
# 6.5 REDIS (Queue Persistence & FAQ Cache)
# =============================================================================
REDIS_URL=redis://localhost:6379/0


# =============================================================================
# 7. SECURITY & PERFORMANCE
# =============================================================================
MAX_CONCURRENT_LLM_CALLS=10

# JWT / SSO / RBAC
# AUTH_MODE: "legacy" = old X-Admin-Token headers, "jwt" = enforce JWT Bearer tokens
AUTH_MODE=legacy
AUTH_SECRET_KEY=your-university-sso-secret
AUTH_TOKEN_EXPIRE_SECONDS=86400

# Speech API hardening
SPEECH_REQUIRE_API_KEY=true
SPEECH_ALLOWED_API_KEYS=
SPEECH_RATE_LIMIT_PER_MINUTE=30

# Audit log hardening
AUDIT_LOG_RETENTION_DAYS=30
AUDIT_LOG_MAX_SIZE_MB=20

# Admin Dashboard
ADMIN_TOKEN=super-secret-key

# Dev Dashboard (separate from admin)
DEV_TOKEN=dev-secret-key

# Session Storage
# SESSION_DIR=../memory/session_storage

# =============================================================================
# 7.5 TTS (Text-to-Speech) — Multi-Provider System
# =============================================================================
# Provider: "auto" (OpenAI→Gemini→Edge fallback chain), "openai", "gemini", "edge"
TTS_ENABLED=true
TTS_PROVIDER=auto

# Circuit Breaker
TTS_DISABLE_ON_NETWORK_ERROR=true
TTS_NETWORK_ERROR_COOLDOWN_SECONDS=60
TTS_NETWORK_ERROR_DISABLE_THRESHOLD=3
TTS_MAX_RETRIES=1

# ─── OpenAI TTS (primary — highest quality, streaming) ──────────────────────
# Set a SEPARATE key if your OPENAI_API_KEY points to Groq/non-OpenAI:
# OPENAI_TTS_API_KEY=sk-...
# OPENAI_TTS_BASE_URL=https://api.openai.com/v1   (default)
OPENAI_TTS_MODEL=tts-1
OPENAI_TTS_VOICE=nova
OPENAI_TTS_SPEED=1.0

# ─── Gemini TTS (fallback — auto-detects language, uses Gemini API key) ────
# Uses GEMINI_API_KEY from section 1.1 by default.
GEMINI_TTS_MODEL=gemini-2.5-flash-preview-tts
GEMINI_TTS_VOICE=Kore

# ─── Edge TTS (free final fallback — no API key needed) ─────────────────────
TTS_VOICE_TH=th-TH-NiwatNeural
TTS_VOICE_EN=en-US-GuyNeural
# TTS_VOICE_ZH=zh-CN-YunxiNeural
# TTS_VOICE_JA=ja-JP-KeitaNeural


# =============================================================================
# 8. OBSERVABILITY (OpenTelemetry + Prometheus)
# =============================================================================
OTEL_ENABLED=false
OTEL_SERVICE_NAME=reg01-backend
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_METRICS_PORT=9464
