# .env.example

# ===========================================
#  LLM (Large Language Model) Configuration
# ===========================================

# Select LLM provider: gemini, openai, or local
LLM_PROVIDER=gemini

# API Key for Google Gemini
GEMINI_API_KEY=your_gemini_api_key_here

# Model name (e.g., gemini-2.0-pro, gemini-2.0-flash)
GEMINI_MODEL_NAME=gemini-2.0-flash

# API Key for OpenAI (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL_NAME=gpt-3.5-turbo
OPENAI_BASE_URL=https://api.openai.com/v1

# Configuration for Local Thai LLM (e.g., Chinda Thai LLM 4B, OpenThaiGPT)
# Use this if LLM_PROVIDER=local
LOCAL_API_KEY=ollama
LOCAL_MODEL_NAME=chinda-qwen3-4b
LOCAL_BASE_URL=http://localhost:11434/v1

# ===========================================
#  Server Configuration
# ===========================================

# Host and port for running the application
HOST=0.0.0.0
PORT=5000

# Allowed origins for CORS (use comma-separated values or * for all)
ALLOWED_ORIGINS=*