# =============================================================================
# ENVIRONMENT CONFIGURATION (Example)
# =============================================================================

# =============================================================================
# 1. LLM PROVIDER (เลือกใช้เพียง 1 ค่า)
#    - gemini
#    - openai   (รวม Groq / External OpenAI-compatible)
#    - local    (Ollama / vLLM)
# =============================================================================
LLM_PROVIDER=openai


# =============================================================================
# 1.1 Google Gemini
# =============================================================================
GEMINI_API_KEY=
GEMINI_MODEL_NAME=gemini-3-flash


# =============================================================================
# 1.2 OpenAI / Groq / OpenAI-Compatible
# =============================================================================
OPENAI_API_KEY=
OPENAI_API_KEY2=
# OPENAI_API_KEY_BACKUP=
# Optional: comma-separated keys (used with OPENAI_API_KEY/OPENAI_API_KEY2)
# OPENAI_API_KEYS=
OPENAI_BASE_URL=https://api.groq.com/openai/v1
OPENAI_MODEL_NAME=openai/gpt-oss-120b
# OPENAI_MODEL_NAME=gpt-5-nano


# =============================================================================
# 1.3 Local Model (Ollama / vLLM)
# =============================================================================
LOCAL_API_KEY=ollama
LOCAL_BASE_URL=http://localhost:11434/v1
LOCAL_MODEL_NAME=iapp/chinda-qwen3-4b


# =============================================================================
# 2. SERVER & NETWORK
# =============================================================================
HOST=0.0.0.0
PORT=5000
ALLOWED_ORIGINS=*


# =============================================================================
# 3. CLOUDFLARE TUNNEL
# =============================================================================
# true  = ใช้ Quick Tunnel (ไม่ต้องมีโดเมน)
# false = ใช้ Named Tunnel
USE_QUICK_TUNNEL=true
CLOUDFLARE_TUNNEL_NAME=reg01-tunnel


# =============================================================================
# 4. FACEBOOK MESSENGER WEBHOOK
# =============================================================================
FB_VERIFY_TOKEN=verify123
FB_PAGE_ACCESS_TOKEN=
# Required to verify X-Hub-Signature-256 on incoming webhook requests
FB_APP_SECRET=


# =============================================================================
# 5. RAG / KNOWLEDGE BASE
# =============================================================================
USE_RETRIEVAL_ENGINE=true
RAG_STARTUP_EMBEDDING=true
RAG_STARTUP_PROCESS_PDF=true
RAG_STARTUP_BUILD_HYBRID=true

# PDF_INPUT_FOLDER=./static/docs
# PDF_QUICK_USE_FOLDER=./static/quick_use


# =============================================================================
# 6. SECURITY & PERFORMANCE
# =============================================================================
MAX_CONCURRENT_LLM_CALLS=10

# JWT / SSO
AUTH_SECRET_KEY=your-university-sso-secret

# Speech API hardening
SPEECH_REQUIRE_API_KEY=true
SPEECH_ALLOWED_API_KEYS=
SPEECH_RATE_LIMIT_PER_MINUTE=30

# Audit log hardening
AUDIT_LOG_RETENTION_DAYS=30
AUDIT_LOG_MAX_SIZE_MB=20

# Admin Dashboard
ADMIN_TOKEN=super-secret-key

# Dev Dashboard (separate from admin)
DEV_TOKEN=dev-secret-key

# Session Storage
# SESSION_DIR=../memory/session_storage

# TTS behavior (edge-tts / speech.platform.bing.com)
TTS_ENABLED=true
TTS_DISABLE_ON_NETWORK_ERROR=true
TTS_NETWORK_ERROR_COOLDOWN_SECONDS=300
