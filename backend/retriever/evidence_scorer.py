import logging
import asyncio
from typing import List, Dict, Tuple
import re
from retriever.intent_analyzer import QueryIntent

logger = logging.getLogger("EvidenceScorer")

class EvidenceScorer:
    """
    ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á context chunks
    ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏à‡∏≤‡∏Å: relevance, specificity, recency, source quality
    """
    
    @staticmethod
    async def score_evidence(
        query: str,
        chunks: List[Tuple[Dict, float]],
        intent_analysis: Dict
    ) -> List[Tuple[Dict, float, Dict]]:
        """
        ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏¥‡πâ‡∏ô
        
        Args:
            query: ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            chunks: List of (chunk_dict, retrieval_score)
            intent_analysis: ‡∏ú‡∏•‡∏à‡∏≤‡∏Å IntentAnalyzer
        
        Returns:
            List of (chunk_dict, final_score, score_breakdown)
        """
        if not chunks:
            return []
        
        keywords = intent_analysis.get('keywords', [])
        temporal_refs = intent_analysis.get('temporal_refs', [])
        entities = intent_analysis.get('entities', [])
        
        scored_chunks = []
        
        for chunk_dict, retrieval_score in chunks:
            chunk_text = chunk_dict.get('chunk', '')
            source = chunk_dict.get('source', '')
            
            # 1. Relevance Score (‡∏à‡∏≤‡∏Å retrieval + keyword match)
            relevance = retrieval_score
            
            # 2. Specificity Score (‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô)
            specificity = EvidenceScorer._calculate_specificity(
                chunk_text, 
                keywords, 
                temporal_refs, 
                entities
            )
            
            # 3. Completeness Score (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
            completeness = EvidenceScorer._calculate_completeness(
                chunk_text,
                intent_analysis
            )
            
            # 4. Source Quality Score
            source_quality = EvidenceScorer._calculate_source_quality(source)
            
            # 5. Recency Score (‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
            recency = EvidenceScorer._calculate_recency(chunk_text)
            
            # Combined score with weights
            weights = {
                'relevance': 0.35,
                'specificity': 0.25,
                'completeness': 0.20,
                'source_quality': 0.10,
                'recency': 0.10
            }
            
            final_score = (
                relevance * weights['relevance'] +
                specificity * weights['specificity'] +
                completeness * weights['completeness'] +
                source_quality * weights['source_quality'] +
                recency * weights['recency']
            )
            
            score_breakdown = {
                'relevance': round(relevance, 3),
                'specificity': round(specificity, 3),
                'completeness': round(completeness, 3),
                'source_quality': round(source_quality, 3),
                'recency': round(recency, 3),
                'final': round(final_score, 3)
            }
            
            scored_chunks.append((chunk_dict, final_score, score_breakdown))
        
        # Sort by final score
        scored_chunks.sort(key=lambda x: x[1], reverse=True)
        
        logger.info(f"üìä Evidence scored: top score = {scored_chunks[0][1]:.3f}")
        
        return scored_chunks
    
    @staticmethod
    def _calculate_specificity(
        text: str,
        keywords: List[str],
        temporal_refs: List[str],
        entities: List[str]
    ) -> float:
        """
        ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
        - ‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà/‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        - ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞/‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô
        - ‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        """
        text_lower = text.lower()
        score = 0.0
        
        # Check temporal refs (0.3)
        temporal_count = sum(1 for t in temporal_refs if t.lower() in text_lower)
        score += min(temporal_count / max(len(temporal_refs), 1), 1.0) * 0.3
        
        # Check entities (0.3)
        entity_count = sum(1 for e in entities if e.lower() in text_lower)
        score += min(entity_count / max(len(entities), 1), 1.0) * 0.3
        
        # Check for specific patterns (0.4)
        has_date = bool(re.search(r'\d{1,2}[/-]\d{1,2}[/-]\d{2,4}', text))
        has_time = bool(re.search(r'\d{1,2}:\d{2}', text))
        has_numbers = bool(re.search(r'\d+', text))
        
        pattern_score = (has_date * 0.2 + has_time * 0.1 + has_numbers * 0.1)
        score += pattern_score
        
        return min(score, 1.0)
    
    @staticmethod
    def _calculate_completeness(text: str, intent_analysis: Dict) -> float:
        """
        ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° intent
        - Factual: ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        - Procedural: ‡∏°‡∏µ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Ñ‡∏£‡∏ö
        - Comparative: ‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á 2 ‡∏ù‡πà‡∏≤‡∏¢
        """
        from intent_analyzer import QueryIntent
        
        intent = intent_analysis.get('intent')
        text_lower = text.lower()
        
        if intent == QueryIntent.FACTUAL:
            # ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
            answer_indicators = ['‡∏Ñ‡∏∑‡∏≠', '‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà', '‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô']
            score = sum(0.25 for w in answer_indicators if w in text_lower)
            return min(score, 1.0)
        
        elif intent == QueryIntent.PROCEDURAL:
            # ‡∏°‡∏µ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
            step_indicators = ['‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô', '‡∏Ç‡∏±‡πâ‡∏ô', '‡∏ó‡∏µ‡πà 1', '‡∏ó‡∏µ‡πà 2', '‡∏Å‡πà‡∏≠‡∏ô', '‡∏´‡∏•‡∏±‡∏á', '‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô']
            score = sum(0.15 for w in step_indicators if w in text_lower)
            return min(score, 1.0)
        
        elif intent == QueryIntent.COMPARATIVE:
            # ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
            compare_indicators = ['‡πÅ‡∏ï‡πà', '‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà', '‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞', '‡∏™‡πà‡∏ß‡∏ô', '‡∏Å‡∏£‡∏ì‡∏µ']
            score = sum(0.25 for w in compare_indicators if w in text_lower)
            return min(score, 1.0)
        
        else:
            # Default: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
            length_score = min(len(text) / 500, 1.0)
            return length_score * 0.5 + 0.5
    
    @staticmethod
    def _calculate_source_quality(source: str) -> float:
        """
        ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤
        - ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ > ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        """
        source_lower = source.lower()
        
        # Official documents
        if any(w in source_lower for w in ['regulation', 'announcement', 'policy', '‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö', '‡∏Ç‡πâ‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö']):
            return 1.0
        
        # Calendar/Schedule
        if any(w in source_lower for w in ['calendar', 'schedule', '‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô']):
            return 0.9
        
        # Guidelines
        if any(w in source_lower for w in ['guide', 'manual', '‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠', '‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á']):
            return 0.8
        
        # General info
        return 0.6
    
    @staticmethod
    def _calculate_recency(text: str) -> float:
        """
        ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏à‡∏≤‡∏Å‡∏õ‡∏µ‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤)
        ‡∏õ‡∏µ 2568 = 1.0, ‡∏õ‡∏µ 2567 = 0.8, ‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏ß‡πà‡∏≤ = 0.5
        """
        # Find academic year
        years = re.findall(r'25[0-9]{2}', text)
        
        if not years:
            return 0.5  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏µ = ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        
        latest_year = max(int(y) for y in years)
        
        if latest_year >= 2568:
            return 1.0
        elif latest_year >= 2567:
            return 0.8
        elif latest_year >= 2566:
            return 0.6
        else:
            return 0.4
    
    @staticmethod
    async def explain_scores(
        top_chunks: List[Tuple[Dict, float, Dict]],
        n: int = 3
    ) -> str:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö top N chunks
        ‡πÄ‡∏û‡∏∑‡πà‡∏≠ debug ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
        """
        if not top_chunks:
            return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô"
        
        explanations = []
        
        for i, (chunk_dict, final_score, breakdown) in enumerate(top_chunks[:n], 1):
            chunk_preview = chunk_dict.get('chunk', '')[:100]
            source = chunk_dict.get('source', '').split('/')[-1]
            
            exp = f"""
Chunk #{i} (Score: {final_score:.3f})
Source: {source}
Preview: {chunk_preview}...
Breakdown:
  - Relevance: {breakdown['relevance']:.3f}
  - Specificity: {breakdown['specificity']:.3f}
  - Completeness: {breakdown['completeness']:.3f}
  - Source Quality: {breakdown['source_quality']:.3f}
  - Recency: {breakdown['recency']:.3f}
"""
            explanations.append(exp)
        
        return "\n".join(explanations)

# Global singleton
evidence_scorer = EvidenceScorer()
