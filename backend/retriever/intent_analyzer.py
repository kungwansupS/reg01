import logging
import asyncio
from typing import Dict, List
from enum import Enum

logger = logging.getLogger("IntentAnalyzer")

class QueryIntent(Enum):
    """‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
    FACTUAL = "factual"
    PROCEDURAL = "procedural"
    COMPARATIVE = "comparative"
    ANALYTICAL = "analytical"
    CONVERSATIONAL = "conversational"

class IntentAnalyzer:
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤"""
    
    @staticmethod
    async def analyze_intent(query: str) -> Dict:
        """
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå intent ‡πÅ‡∏•‡∏∞‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        
        Returns:
            {
                "intent": QueryIntent,
                "keywords": List[str],
                "temporal_refs": List[str],
                "entities": List[str],
                "confidence": float
            }
        """
        try:
            from app.utils.llm.llm_model import get_llm_model
            from app.config import LLM_PROVIDER, GEMINI_MODEL_NAME, OPENAI_MODEL_NAME, LOCAL_MODEL_NAME
            
            prompt = f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:
"{query}"

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°):
{{
    "intent": "factual",
    "keywords": ["‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç1", "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç2"],
    "temporal_refs": ["2568", "‡∏†‡∏≤‡∏Ñ 1"],
    "entities": ["‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô"],
    "confidence": 0.9
}}

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ intent:
- factual: ‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
- procedural: ‡∏ñ‡∏≤‡∏°‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£/‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
- comparative: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
- analytical: ‡∏Ç‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå/‡∏™‡∏£‡∏∏‡∏õ
- conversational: ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ"""
            
            model = get_llm_model()
            
            if LLM_PROVIDER == "gemini":
                response = await model.aio.models.generate_content(
                    model=GEMINI_MODEL_NAME,
                    contents=prompt
                )
                result = response.text.strip()
            else:
                m_name = OPENAI_MODEL_NAME if LLM_PROVIDER == "openai" else LOCAL_MODEL_NAME
                response = await model.chat.completions.create(
                    model=m_name,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0
                )
                result = response.choices[0].message.content.strip()
            
            import json
            import re
            
            # Clean response
            result = re.sub(r'```json\s*|\s*```', '', result).strip()
            
            # Try to extract JSON object (handle extra text after JSON)
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', result, re.DOTALL)
            if json_match:
                result = json_match.group(0)
            
            # Parse JSON with fallback
            try:
                # Try to decode just the first complete JSON object
                decoder = json.JSONDecoder()
                analysis, _ = decoder.raw_decode(result)
            except json.JSONDecodeError:
                # Fallback: standard parse
                analysis = json.loads(result)
            
            # Convert intent string to enum
            try:
                intent_str = analysis.get('intent', 'factual')
                analysis['intent'] = QueryIntent(intent_str)
            except (KeyError, ValueError):
                analysis['intent'] = QueryIntent.FACTUAL
            
            # Ensure all required fields exist
            analysis.setdefault('keywords', [])
            analysis.setdefault('temporal_refs', [])
            analysis.setdefault('entities', [])
            analysis.setdefault('confidence', 0.5)
            
            logger.info(f"üéØ Intent: {analysis['intent'].value} (confidence: {analysis.get('confidence', 0):.2f})")
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå Intent analysis failed: {e}")
            return IntentAnalyzer._fallback_analysis(query)
    
    @staticmethod
    def _fallback_analysis(query: str) -> Dict:
        """Simple pattern-based fallback"""
        query_lower = query.lower()
        
        # Detect intent by keywords
        if any(w in query_lower for w in ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà', '‡∏ß‡∏±‡∏ô‡πÑ‡∏´‡∏ô', '‡∏Å‡∏µ‡πà‡πÇ‡∏°‡∏á']):
            intent = QueryIntent.FACTUAL
        elif any(w in query_lower for w in ['‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£', '‡∏¢‡∏±‡∏á‡πÑ‡∏á', '‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô', '‡∏ß‡∏¥‡∏ò‡∏µ']):
            intent = QueryIntent.PROCEDURAL
        elif any(w in query_lower for w in ['‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô', '‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô', '‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö']):
            intent = QueryIntent.COMPARATIVE
        elif any(w in query_lower for w in ['‡∏™‡∏£‡∏∏‡∏õ', '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå', '‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢']):
            intent = QueryIntent.ANALYTICAL
        else:
            intent = QueryIntent.FACTUAL
        
        return {
            'intent': intent,
            'keywords': [],
            'temporal_refs': [],
            'entities': [],
            'confidence': 0.5
        }
    
    @staticmethod
    def get_search_params(analysis: Dict) -> Dict:
        """
        ‡πÅ‡∏õ‡∏•‡∏á intent ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö search
        
        Returns:
            {
                "k_multiplier": int,
                "dense_weight": float,
                "sparse_weight": float,
                "keyword_boost": float,
                "need_diversity": bool
            }
        """
        intent = analysis.get('intent', QueryIntent.FACTUAL)
        confidence = analysis.get('confidence', 0.5)
        
        if intent == QueryIntent.FACTUAL:
            return {
                'k_multiplier': 2,
                'dense_weight': 0.4,
                'sparse_weight': 0.6,
                'keyword_boost': 0.4,
                'need_diversity': False
            }
        
        elif intent == QueryIntent.PROCEDURAL:
            return {
                'k_multiplier': 3,
                'dense_weight': 0.5,
                'sparse_weight': 0.5,
                'keyword_boost': 0.3,
                'need_diversity': True
            }
        
        elif intent == QueryIntent.COMPARATIVE:
            return {
                'k_multiplier': 4,
                'dense_weight': 0.6,
                'sparse_weight': 0.4,
                'keyword_boost': 0.2,
                'need_diversity': True
            }
        
        elif intent == QueryIntent.ANALYTICAL:
            return {
                'k_multiplier': 4,
                'dense_weight': 0.7,
                'sparse_weight': 0.3,
                'keyword_boost': 0.2,
                'need_diversity': True
            }
        
        else:  # CONVERSATIONAL
            return {
                'k_multiplier': 1,
                'dense_weight': 0.6,
                'sparse_weight': 0.4,
                'keyword_boost': 0.1,
                'need_diversity': False
            }

# Global singleton
intent_analyzer = IntentAnalyzer()