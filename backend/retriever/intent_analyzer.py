import logging
import asyncio
from typing import Dict, List
from enum import Enum

logger = logging.getLogger("IntentAnalyzer")

class QueryIntent(Enum):
    """‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
    FACTUAL = "factual"              # ‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á (‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà, ‡πÄ‡∏ß‡∏•‡∏≤, ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà)
    PROCEDURAL = "procedural"        # ‡∏ñ‡∏≤‡∏°‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£/‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
    COMPARATIVE = "comparative"      # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    ANALYTICAL = "analytical"        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå/‡∏™‡∏£‡∏∏‡∏õ
    CONVERSATIONAL = "conversational" # ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

class IntentAnalyzer:
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    """
    
    @staticmethod
    async def analyze_intent(query: str) -> Dict:
        """
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå intent ‡πÅ‡∏•‡∏∞‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        
        Returns:
            {
                "intent": QueryIntent,
                "keywords": List[str],
                "temporal_refs": List[str],  # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà, ‡∏õ‡∏µ, ‡∏†‡∏≤‡∏Ñ
                "entities": List[str],        # ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞, ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô
                "confidence": float
            }
        """
        try:
            from app.utils.llm.llm_model import get_llm_model
            from app.config import LLM_PROVIDER, GEMINI_MODEL_NAME, OPENAI_MODEL_NAME, LOCAL_MODEL_NAME
            
            prompt = f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:
"{query}"

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON:
{{
    "intent": "factual|procedural|comparative|analytical|conversational",
    "keywords": ["‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç1", "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç2", ...],
    "temporal_refs": ["2568", "‡∏†‡∏≤‡∏Ñ 1", ...],
    "entities": ["‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô", "‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°", ...],
    "confidence": 0.0-1.0
}}

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ intent:
- factual: ‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà, ‡πÄ‡∏ß‡∏•‡∏≤, ‡∏ä‡∏∑‡πà‡∏≠)
- procedural: ‡∏ñ‡∏≤‡∏°‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£/‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô (‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£, ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏¢‡∏±‡∏á‡πÑ‡∏á)
- comparative: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö (‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£, ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤)
- analytical: ‡∏Ç‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå/‡∏™‡∏£‡∏∏‡∏õ (‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢, ‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á)
- conversational: ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ, ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì)

‡∏Å‡∏é:
- keywords: ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏™‡∏π‡∏á 5-10 ‡∏Ñ‡∏≥
- temporal_refs: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏•‡∏≤ (‡∏õ‡∏µ/‡∏†‡∏≤‡∏Ñ/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô/‡∏ß‡∏±‡∏ô)
- entities: ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
- confidence: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î intent (0.7+ = ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à)
"""
            
            model = get_llm_model()
            
            if LLM_PROVIDER == "gemini":
                response = await model.aio.models.generate_content(
                    model=GEMINI_MODEL_NAME,
                    contents=prompt
                )
                result = response.text.strip()
            else:
                m_name = OPENAI_MODEL_NAME if LLM_PROVIDER == "openai" else LOCAL_MODEL_NAME
                response = await model.chat.completions.create(
                    model=m_name,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0
                )
                result = response.choices[0].message.content.strip()
            
            import json
            import re
            result = re.sub(r'```json\s*|\s*```', '', result).strip()
            
            analysis = json.loads(result)
            
            # Convert intent string to enum
            try:
                analysis['intent'] = QueryIntent(analysis['intent'])
            except:
                analysis['intent'] = QueryIntent.FACTUAL
            
            logger.info(f"üéØ Intent: {analysis['intent'].value} (confidence: {analysis.get('confidence', 0):.2f})")
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå Intent analysis failed: {e}")
            # Fallback: simple pattern matching
            return IntentAnalyzer._fallback_analysis(query)
    
    @staticmethod
    def _fallback_analysis(query: str) -> Dict:
        """Simple pattern-based fallback"""
        query_lower = query.lower()
        
        # Detect intent by keywords
        if any(w in query_lower for w in ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà', '‡∏ß‡∏±‡∏ô‡πÑ‡∏´‡∏ô', '‡∏Å‡∏µ‡πà‡πÇ‡∏°‡∏á']):
            intent = QueryIntent.FACTUAL
        elif any(w in query_lower for w in ['‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£', '‡∏¢‡∏±‡∏á‡πÑ‡∏á', '‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô', '‡∏ß‡∏¥‡∏ò‡∏µ']):
            intent = QueryIntent.PROCEDURAL
        elif any(w in query_lower for w in ['‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô', '‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô', '‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö']):
            intent = QueryIntent.COMPARATIVE
        elif any(w in query_lower for w in ['‡∏™‡∏£‡∏∏‡∏õ', '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå', '‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢']):
            intent = QueryIntent.ANALYTICAL
        else:
            intent = QueryIntent.FACTUAL
        
        return {
            'intent': intent,
            'keywords': [],
            'temporal_refs': [],
            'entities': [],
            'confidence': 0.5
        }
    
    @staticmethod
    def get_search_params(analysis: Dict) -> Dict:
        """
        ‡πÅ‡∏õ‡∏•‡∏á intent ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö search
        
        Returns:
            {
                "k_multiplier": int,     # ‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ k ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£
                "dense_weight": float,   # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å semantic
                "sparse_weight": float,  # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å keyword
                "keyword_boost": float,  # boost ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö keyword match
                "need_diversity": bool   # ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢
            }
        """
        intent = analysis.get('intent', QueryIntent.FACTUAL)
        confidence = analysis.get('confidence', 0.5)
        
        if intent == QueryIntent.FACTUAL:
            # Factual: ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á
            return {
                'k_multiplier': 2,
                'dense_weight': 0.4,
                'sparse_weight': 0.6,  # ‡πÄ‡∏ô‡πâ‡∏ô keyword
                'keyword_boost': 0.4,
                'need_diversity': False
            }
        
        elif intent == QueryIntent.PROCEDURAL:
            # Procedural: ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
            return {
                'k_multiplier': 3,
                'dense_weight': 0.5,
                'sparse_weight': 0.5,
                'keyword_boost': 0.3,
                'need_diversity': True
            }
        
        elif intent == QueryIntent.COMPARATIVE:
            # Comparative: ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡∏•‡πà‡∏á
            return {
                'k_multiplier': 4,
                'dense_weight': 0.6,
                'sparse_weight': 0.4,
                'keyword_boost': 0.2,
                'need_diversity': True
            }
        
        elif intent == QueryIntent.ANALYTICAL:
            # Analytical: ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏ß‡πâ‡∏≤‡∏á
            return {
                'k_multiplier': 4,
                'dense_weight': 0.7,
                'sparse_weight': 0.3,
                'keyword_boost': 0.2,
                'need_diversity': True
            }
        
        else:  # CONVERSATIONAL
            # Conversational: ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡∏Å
            return {
                'k_multiplier': 1,
                'dense_weight': 0.6,
                'sparse_weight': 0.4,
                'keyword_boost': 0.1,
                'need_diversity': False
            }

# Global singleton
intent_analyzer = IntentAnalyzer()
